{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import dgl\n",
    "import pickle\n",
    "from utils import HGT\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.load_graphs('training_data/graph.dgl')\n",
    "graph = graph[0][0]\n",
    "\n",
    "with open('training_data/train.obj', 'rb') as fp:\n",
    "\ttrain = pickle.load(fp)\n",
    "\n",
    "with open('training_data/val.obj', 'rb') as fp:\n",
    "\tval = pickle.load(fp)\n",
    "\n",
    "with open('training_data/test.obj', 'rb') as fp:\n",
    "\ttest = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150243"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes('business').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r3/89932hws5rg2xwsqck66y26r0000gp/T/ipykernel_14178/4158148776.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  g.ndata['feat'] = {k: torch.tensor(v, dtype=torch.float32) for k, v in graph.ndata['feat'].items() }\n"
     ]
    }
   ],
   "source": [
    "edges = {}\n",
    "for canonical_etype in graph.canonical_etypes:\n",
    "    edges[canonical_etype] = graph.edges(etype=canonical_etype)\n",
    "\n",
    "edges[('category', 'category_to_business', 'business')] = (graph.edges(etype='business_has_category')[1], graph.edges(etype='business_has_category')[0])\n",
    "edges[('business', 'business_to_review', 'review')] = (graph.edges(etype='review_to_business')[1], graph.edges(etype='review_to_business')[0])\n",
    "edges[('business', 'business_to_tip', 'tip')] = (graph.edges(etype='tip_to_business')[1], graph.edges(etype='tip_to_business')[0])\n",
    "edges[('review', 'review_to_user', 'user')] = (graph.edges(etype='user_to_review')[1], graph.edges(etype='user_to_review')[0])\n",
    "edges[('tip', 'tip_to_user', 'user')] = (graph.edges(etype='user_to_tip')[1], graph.edges(etype='user_to_tip')[0])\n",
    "\n",
    "num_nodes_dict = {} \n",
    "for ntype in graph.ntypes:\n",
    "    num_nodes_dict[ntype] = graph.nodes(ntype).shape[0]\n",
    "\n",
    "g = dgl.heterograph(edges, num_nodes_dict = num_nodes_dict)\n",
    "g.ndata['feat'] = {k: torch.tensor(v, dtype=torch.float32) for k, v in graph.ndata['feat'].items() }\n",
    "del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_nodes of Graph(num_nodes={'business': 150243, 'category': 1311, 'review': 6339837, 'tip': 908878, 'user': 1987897},\n",
       "      num_edges={('business', 'business_has_category', 'category'): 668592, ('business', 'business_to_review', 'review'): 6339837, ('business', 'business_to_tip', 'tip'): 908878, ('category', 'category_to_business', 'business'): 668592, ('review', 'review_to_business', 'business'): 6339837, ('review', 'review_to_user', 'user'): 6339837, ('tip', 'tip_to_business', 'business'): 908878, ('tip', 'tip_to_user', 'user'): 908878, ('user', 'user_to_review', 'review'): 6339837, ('user', 'user_to_tip', 'tip'): 908878, ('user', 'user_to_user', 'user'): 437928},\n",
       "      metagraph=[('business', 'category', 'business_has_category'), ('business', 'review', 'business_to_review'), ('business', 'tip', 'business_to_tip'), ('category', 'business', 'category_to_business'), ('review', 'business', 'review_to_business'), ('review', 'user', 'review_to_user'), ('tip', 'business', 'tip_to_business'), ('tip', 'user', 'tip_to_user'), ('user', 'review', 'user_to_review'), ('user', 'tip', 'user_to_tip'), ('user', 'user', 'user_to_user')])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = { ntype: g.ntypes.index(ntype) for ntype in g.ntypes }\n",
    "edge_dict = { canonical_etype: g.canonical_etypes.index(canonical_etype) for canonical_etype in g.canonical_etypes }\n",
    "feature_dim_dict = { ntype: g.ndata['feat'][ntype].shape[1] for ntype in g.ntypes }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': 0, 'category': 1, 'review': 2, 'tip': 3, 'user': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGT(node_dict, edge_dict, feature_dim_dict, n_hid=256, n_out=128, n_layers=4, n_heads=8, use_norm=False)\n",
    "opt = torch.optim.AdamW(model.parameters(), 1e-4)\n",
    "sampler = dgl.dataloading.NeighborSampler([24, 24, 24, 24])\n",
    "criterion = torch.nn.MarginRankingLoss(margin=0.1)\n",
    "# dgl.dataloading.NeighborSampler([\n",
    "#     {('user', 'follows', 'user'): 5,\n",
    "#      ('user', 'plays', 'game'): 4,\n",
    "#      ('game', 'played-by', 'user'): 3}] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_ids = list(range(train['pos'][0].shape[0]))\n",
    "train_neg_ids = list(range(train['neg'][0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_neg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat']['category'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(g, model, pos_ids, neg_ids, relation_tuple, sampler, batch_size):\n",
    "    pos_users = torch.index_select(relation_tuple['pos'][0], 0, torch.tensor(pos_ids))\n",
    "    pos_users_unique, pos_users_inverse = torch.unique(pos_users, return_inverse=True)\n",
    "    pos_block_user = [blocks for _, _, blocks in dgl.dataloading.DataLoader(\n",
    "        g, {'user': pos_users_unique}, sampler,\n",
    "        batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)][0]\n",
    "\n",
    "    pos_business = torch.index_select(relation_tuple['pos'][1], 0, torch.tensor(pos_ids))\n",
    "    pos_business_unique, pos_business_inverse = torch.unique(pos_business, return_inverse=True)\n",
    "    pos_block_business = [blocks for _, _, blocks in dgl.dataloading.DataLoader(\n",
    "        g, {'business': pos_business_unique }, sampler,\n",
    "        batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)][0]\n",
    "    \n",
    "    neg_users = torch.index_select(relation_tuple['neg'][0], 0, torch.tensor(neg_ids))\n",
    "    neg_users_unique, neg_users_inverse = torch.unique(neg_users, return_inverse=True)\n",
    "    neg_block_user = [blocks for _, _, blocks in dgl.dataloading.DataLoader(\n",
    "        g, {'user': neg_users_unique }, sampler,\n",
    "        batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)][0]\n",
    "    \n",
    "    neg_business = torch.index_select(relation_tuple['neg'][1], 0, torch.tensor(neg_ids))\n",
    "    neg_business_unique, neg_business_inverse = torch.unique(neg_business, return_inverse=True)\n",
    "    neg_block_business = [blocks for _, _, blocks in dgl.dataloading.DataLoader(\n",
    "        g, {'business': neg_business_unique }, sampler,\n",
    "        batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)][0]\n",
    "\n",
    "    pos_user_logits = torch.index_select(model(pos_block_user, 'user'), 0, pos_users_inverse)\n",
    "    pos_business_logits = torch.index_select(model(pos_block_business, 'business'), 0, pos_business_inverse)\n",
    "    neg_user_logits = torch.index_select(model(neg_block_user, 'user'), 0, neg_users_inverse)\n",
    "    neg_business_logits = torch.index_select(model(neg_block_business, 'business'), 0, neg_business_inverse)\n",
    "    return pos_user_logits, pos_business_logits, neg_user_logits, neg_business_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippominutella/miniconda3/lib/python3.10/site-packages/dgl/dataloading/dataloader.py:869: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
      "  dgl_warning(f'Dataloader CPU affinity opt is not enabled, consider switching it on '\n",
      "/Users/filippominutella/miniconda3/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10345187783241272\n",
      "0.10159596800804138\n",
      "0.10099367797374725\n",
      "0.10106093436479568\n",
      "0.10034532845020294\n",
      "0.0988563820719719\n",
      "0.09787221252918243\n",
      "0.09768624603748322\n",
      "0.09934961050748825\n",
      "0.09831322729587555\n",
      "0.09636179357767105\n",
      "0.09732170403003693\n",
      "0.09519215673208237\n",
      "0.09284672141075134\n",
      "0.0941537618637085\n",
      "0.09199901670217514\n",
      "0.09243879467248917\n",
      "0.09165386855602264\n",
      "0.08929087966680527\n",
      "0.09127331525087357\n",
      "0.09083104133605957\n",
      "0.09100508689880371\n",
      "0.08245374262332916\n",
      "0.08667824417352676\n",
      "0.0898139476776123\n",
      "0.08351676166057587\n",
      "0.08246343582868576\n",
      "0.08488159626722336\n",
      "0.08278439939022064\n",
      "0.07845573872327805\n",
      "0.07928439974784851\n",
      "0.07706654071807861\n",
      "0.08241486549377441\n",
      "0.07168830186128616\n",
      "0.08841340243816376\n",
      "0.07437971234321594\n",
      "0.08074168115854263\n",
      "0.06672988086938858\n",
      "0.07615679502487183\n",
      "0.06875477731227875\n",
      "0.07358470559120178\n",
      "0.07405633479356766\n",
      "0.07372436672449112\n",
      "0.07940811663866043\n",
      "0.0912003368139267\n",
      "0.07253234088420868\n",
      "0.07213099300861359\n",
      "0.05858322232961655\n",
      "0.06751268357038498\n",
      "0.06283405423164368\n",
      "0.06764808297157288\n",
      "0.0694303959608078\n",
      "0.05465422570705414\n",
      "0.07127785682678223\n",
      "0.05784027650952339\n",
      "0.07904749363660812\n",
      "0.05902590602636337\n",
      "0.06271258741617203\n",
      "0.060394927859306335\n",
      "0.05636635422706604\n",
      "0.05634613707661629\n",
      "0.06616203486919403\n",
      "0.05407073348760605\n",
      "0.058277711272239685\n",
      "0.055182263255119324\n",
      "0.060506127774715424\n",
      "0.05854090675711632\n",
      "0.0475226528942585\n",
      "0.04306479170918465\n",
      "0.0414007306098938\n",
      "0.03824591636657715\n",
      "0.04608847200870514\n",
      "0.0434967502951622\n",
      "0.051444441080093384\n",
      "0.048742011189460754\n",
      "0.040651559829711914\n",
      "0.05360261723399162\n",
      "0.049895547330379486\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m neg_score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(neg_user_logits\u001b[39m.\u001b[39mview(batch_size, \u001b[39m1\u001b[39m, model\u001b[39m.\u001b[39mn_out), neg_business_logits\u001b[39m.\u001b[39mview(batch_size, model\u001b[39m.\u001b[39mn_out, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m criterion(pos_score, neg_score, torch\u001b[39m.\u001b[39mones(batch_size))\n\u001b[0;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     18\u001b[0m opt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/function.py:264\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBackwardCFunction\u001b[39;00m(_C\u001b[39m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m    265\u001b[0m         \u001b[39m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[39m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         backward_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cls\u001b[39m.\u001b[39mbackward  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         vjp_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cls\u001b[39m.\u001b[39mvjp  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def split(list_a, chunk_size):\n",
    "    for i in range(0, len(list_a), chunk_size):\n",
    "        yield list_a[i:i + chunk_size]\n",
    "\n",
    "batch_size = 64\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    random.shuffle(train_pos_ids)\n",
    "    random.shuffle(train_neg_ids)\n",
    "    for batch in split(list(zip(train_pos_ids, train_neg_ids)), batch_size):\n",
    "        opt.zero_grad()\n",
    "        pos_ids, neg_ids = list(zip(*batch))\n",
    "        pos_user_logits, pos_business_logits, neg_user_logits, neg_business_logits = predict(g, model, pos_ids, neg_ids, train, sampler, batch_size)\n",
    "        pos_score = torch.bmm(pos_user_logits.view(batch_size, 1, model.n_out), pos_business_logits.view(batch_size, model.n_out, 1)).squeeze()\n",
    "        neg_score = torch.bmm(neg_user_logits.view(batch_size, 1, model.n_out), neg_business_logits.view(batch_size, model.n_out, 1)).squeeze()\n",
    "        loss = criterion(pos_score, neg_score, torch.ones(batch_size))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        print(loss.item())\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pos_id = train['pos'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_business = train['pos'][1][train['pos'][0] == train['pos'][0][0]]\n",
    "neg_business = train['neg'][1][train['neg'][0] == train['pos'][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([111108,  80217,  25553,  73239,  66461,  23450,  20934, 120272,  86879,\n",
       "         38967,  84152,  13612])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120919])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv('preprocessed/user_ids.csv')\n",
    "business_df = pd.read_csv('preprocessed/business_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id:ID    U438yUH5aBVntI_CbVt8jg\n",
       "Name: 207300, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.loc[user_pos_id.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id:ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111108</th>\n",
       "      <td>a0d09197752174e42a05ff2cf445fa91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80217</th>\n",
       "      <td>064a4a8a97aa17167a9427a19aca98ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25553</th>\n",
       "      <td>33d2e8ccd5b8f4d14ad8e83b11444bc0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73239</th>\n",
       "      <td>3f2388115a0b7cc98b242191fdad7bf4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66461</th>\n",
       "      <td>8e64483dbe1cb3d0662df91b83867345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23450</th>\n",
       "      <td>1fd668fc67cb62812e523ab153b411ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20934</th>\n",
       "      <td>f30c7b0034d553e0da7e07811841868b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120272</th>\n",
       "      <td>3d6954a8431403d9e6e8b293a943d6d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86879</th>\n",
       "      <td>15aaec95654f4ba868dfb2547ec72193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38967</th>\n",
       "      <td>e1756e58d54f74ce2392ec5fe40d0eb5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84152</th>\n",
       "      <td>dd113aed595c4b7a50981891885def1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13612</th>\n",
       "      <td>05e514dcebb721d1b064977dc3c71489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          business_id:ID\n",
       "111108  a0d09197752174e42a05ff2cf445fa91\n",
       "80217   064a4a8a97aa17167a9427a19aca98ef\n",
       "25553   33d2e8ccd5b8f4d14ad8e83b11444bc0\n",
       "73239   3f2388115a0b7cc98b242191fdad7bf4\n",
       "66461   8e64483dbe1cb3d0662df91b83867345\n",
       "23450   1fd668fc67cb62812e523ab153b411ce\n",
       "20934   f30c7b0034d553e0da7e07811841868b\n",
       "120272  3d6954a8431403d9e6e8b293a943d6d2\n",
       "86879   15aaec95654f4ba868dfb2547ec72193\n",
       "38967   e1756e58d54f74ce2392ec5fe40d0eb5\n",
       "84152   dd113aed595c4b7a50981891885def1a\n",
       "13612   05e514dcebb721d1b064977dc3c71489"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.loc[pos_business.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id:ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120919</th>\n",
       "      <td>82ad544c4332ea410b5018b6b69b5a2d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          business_id:ID\n",
       "120919  82ad544c4332ea410b5018b6b69b5a2d"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.loc[neg_business.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filippominutella/miniconda3/lib/python3.10/site-packages/dgl/dataloading/dataloader.py:869: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
      "  dgl_warning(f'Dataloader CPU affinity opt is not enabled, consider switching it on '\n",
      "/Users/filippominutella/miniconda3/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "block_user = [blocks for _, _, blocks in dgl.dataloading.DataLoader(\n",
    "    g, {'user': [user_pos_id] }, sampler,\n",
    "    batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)][0]\n",
    "\n",
    "pos_block_business = [blocks for _, _, blocks in dgl.dataloading.DataLoader(\n",
    "    g, {'business': pos_business }, sampler,\n",
    "    batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)][0]\n",
    "\n",
    "neg_block_business = [blocks for _, _, blocks in dgl.dataloading.DataLoader(\n",
    "    g, {'business': neg_business }, sampler,\n",
    "    batch_size=batch_size, shuffle=False, drop_last=False, num_workers=1)][0]\n",
    "\n",
    "user = model(block_user, 'user')[0]\n",
    "p_business = model(pos_block_business, 'business')\n",
    "n_business = model(neg_block_business, 'business')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5728, 0.5628, 0.5803, 0.5380, 0.5070, 0.5362, 0.5807, 0.5817, 0.5664,\n",
       "        0.5480, 0.5818, 0.5637], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(user.repeat(p_business.shape[0], 1).view(p_business.shape[0], 1, model.n_out), p_business.view(p_business.shape[0], model.n_out, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5402, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(user.repeat(n_business.shape[0], 1).view(n_business.shape[0], 1, model.n_out), n_business.view(n_business.shape[0], model.n_out, 1)).squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
